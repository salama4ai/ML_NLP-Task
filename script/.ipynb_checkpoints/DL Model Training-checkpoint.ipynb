{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b533e64b-5c83-469f-bc42-0a0718bb73d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #installing requirements for pytorch\n",
    "# !conda install astunparse numpy ninja pyyaml mkl mkl-include setuptools cmake cffi typing_extensions future six requests dataclasses\n",
    "# !conda install -c conda-forge libuv=1.39\n",
    "\n",
    "# #installing stable version of pytorch with python/pip , cuda-11.3 on windows10 in march-2022\n",
    "# !conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch\n",
    "\n",
    "# # packages needed for arabert\n",
    "# !pip install -U pip\n",
    "# !pip install transformers \n",
    "# !pip install farasapy\n",
    "# !pip install iopath\n",
    "# !pip install pyarabic\n",
    "# !pip install huggingface-hub datasets\n",
    "# !conda install -c huggingface transformers\n",
    "# i know that some packages installed more than one time, when i install package\n",
    "# and face problem and reinstall it again -by pip as example- i write that here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ea7b3fec-d3a7-4dd4-a53c-7078d168fa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from arabert.preprocess import ArabertPreprocessor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "984c80ea-a472-449f-9331-dde1a66cfaec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\aim\\\\script'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the current working directory path\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# model_name = \"aubmindlab/bert-base-arabertv2\"\n",
    "model_name = \"aubmindlab/bert-large-arabertv2\"\n",
    "text = \"ولن نبالغ إذا قلنا إن هاتف أو كمبيوتر المكتب في زمننا هذا ضروري\"\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "144491e6-6313-4cdc-89e1-139b879c6fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/aub-mind/arabert.git {cwd}\n",
    "# !git clone https://huggingface.co/aubmindlab/bert-large-arabertv2 {cwd}\\..\\init_arabert_models\\large-arabertv2\n",
    "# !git clone https://huggingface.co/aubmindlab/bert-base-arabertv2 {cwd}\\..\\init_arabert_models\\base-arabertv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93bc5c28-f957-4fd3-9490-f71c1cf1dad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at aubmindlab/bert-large-arabertv2 were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "arabert_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "arabert_model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "633a4e62-d1b6-4d66-866c-4ee71762dc34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ولن',\n",
       " 'نبالغ',\n",
       " 'إذا',\n",
       " 'قلن',\n",
       " '##ا',\n",
       " 'إن',\n",
       " 'هاتف',\n",
       " 'أو',\n",
       " 'كمبيوتر',\n",
       " 'الم',\n",
       " '##كتب',\n",
       " 'في',\n",
       " 'زمن',\n",
       " '##نا',\n",
       " 'هذا',\n",
       " 'ضروري']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arabert_tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40102dc6-1f59-4d5f-8afa-7deaf2a91aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from arabert.preprocess import ArabertPreprocessor\n",
    "# arabert_prep = ArabertPreprocessor(model_name=model_name)\n",
    "\n",
    "# arabert_prep.preprocess(text)\n",
    "# >>>\"و+ لن نبالغ إذا قل +نا إن هاتف أو كمبيوتر ال+ مكتب في زمن +نا هذا ضروري\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "61b1b0da-00ed-4844-9cef-caf517dcd0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>dialect</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1175358310087892992</th>\n",
       "      <td>لكن بالنهايه ينتفض يغير</td>\n",
       "      <td>IQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175416117793349632</th>\n",
       "      <td>يعني هذا محسوب علي البشر حيونه وحشيه وتطلبون ...</td>\n",
       "      <td>IQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175450108898565888</th>\n",
       "      <td>مبين من كلامه خليجي</td>\n",
       "      <td>IQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175471073770573824</th>\n",
       "      <td>يسلملي مرورك وروحك الحلوه</td>\n",
       "      <td>IQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175496913145217024</th>\n",
       "      <td>وين هل الغيبه اخ محمد</td>\n",
       "      <td>IQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019484980282580992</th>\n",
       "      <td>مبسوطين منك الي باسطانا</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021083283709407232</th>\n",
       "      <td>واله ماينده ابش يختي</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017477537889431552</th>\n",
       "      <td>شو عملنا لك حنا تهربي منا احنا مساكين ليش بتع...</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022430374696239232</th>\n",
       "      <td>اله يبارك فيها وبالعافيه</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022409931029458944</th>\n",
       "      <td>السحله ضيفي ي بتطلع لك سحليه</td>\n",
       "      <td>BH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458197 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   txt dialect\n",
       "id                                                                            \n",
       "1175358310087892992                           لكن بالنهايه ينتفض يغير       IQ\n",
       "1175416117793349632   يعني هذا محسوب علي البشر حيونه وحشيه وتطلبون ...      IQ\n",
       "1175450108898565888                                مبين من كلامه خليجي      IQ\n",
       "1175471073770573824                         يسلملي مرورك وروحك الحلوه       IQ\n",
       "1175496913145217024                             وين هل الغيبه اخ محمد       IQ\n",
       "...                                                                ...     ...\n",
       "1019484980282580992                           مبسوطين منك الي باسطانا       BH\n",
       "1021083283709407232                               واله ماينده ابش يختي      BH\n",
       "1017477537889431552   شو عملنا لك حنا تهربي منا احنا مساكين ليش بتع...      BH\n",
       "1022430374696239232                          اله يبارك فيها وبالعافيه       BH\n",
       "1022409931029458944                      السحله ضيفي ي بتطلع لك سحليه       BH\n",
       "\n",
       "[458197 rows x 2 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_df = pd.read_csv(\"../csv_files/cleaned_txt_df.csv\", index_col=\"id\")\n",
    "label_df = pd.read_csv(\"../csv_files/dialect_dataset.csv\", index_col=\"id\")\n",
    "df = pd.merge(txt_df, label_df, left_index=True, right_index=True) # === pd.concat([txt_df, label_df], axis=1)\n",
    "# df = df.reset_index()[[\"txt\", \"dialect\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5b6c8583-456a-405f-b384-ef3b47fb94dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>dialect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>458197</td>\n",
       "      <td>458197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>457511</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td></td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>146</td>\n",
       "      <td>57636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           txt dialect\n",
       "count   458197  458197\n",
       "unique  457511      18\n",
       "top                 EG\n",
       "freq       146   57636"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "89523380-74ba-4c29-9b0a-c3e360d81f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 458197 entries, 1175358310087892992 to 1022409931029458944\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   txt      458197 non-null  object\n",
      " 1   dialect  458197 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 26.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4e29c314-3d25-4122-8119-e4092bec6def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"dialect\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "29875fda-9dfb-488d-a6ba-15ec2f6f602b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"txt\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e1daf5dd-99af-48a4-8718-079cc15bcfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EG    57636\n",
      "PL    43742\n",
      "KW    42109\n",
      "LY    36499\n",
      "QA    31069\n",
      "JO    27921\n",
      "LB    27617\n",
      "SA    26832\n",
      "AE    26296\n",
      "BH    26292\n",
      "OM    19116\n",
      "SY    16242\n",
      "DZ    16183\n",
      "IQ    15497\n",
      "SD    14434\n",
      "MA    11539\n",
      "YE     9927\n",
      "TN     9246\n",
      "Name: dialect, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAilUlEQVR4nO3de7xVZb3v8c+XRVwMCfCCBiaUaAkdCNmipWZWSOYO2y/taG2hsttOPJ12F3W3TfLSsXNqW6ZdN6Smhe7aFceNKWFWlKCIoCyUOykEqIAXClEWv/3H80wYczHnXHNdWNy+79drvdaaz3jGM8ecc8z5m+OyxlcRgZmZHdi67OkFMDOzPc/FwMzMXAzMzMzFwMzMcDEwMzOg655egLY69NBDY9CgQXt6MczM9ikPP/zwsxFxWPP2fbYYDBo0iLlz5+7pxTAz26dI+nOldu8mMjMzFwMzM3MxMDMzXAzMzAwXAzMzw8XAzMxwMTAzM1wMzMwMFwMzM2Mf/g/k9hh02X+1ab5V1723g5fEzGzv4C0DMzNzMTAzMxcDMzPDxcDMzHAxMDMz6iwGklZJekzSfElzc9skSWty23xJZxX6Xy5pmaTFks4stI/NbcskXVZoHyxpTm6/Q1K3jnyQZmZWW2u2DN4RESMiYlSh7frcNiIipgNIOh44HxgKjAW+I6lBUgNwE/Ae4HjggtwX4Gt5rGOATcBF7XtYZmbWGrtjN9E4YGpEbI2IlcAy4MT8sywiVkTEy8BUYJwkAWcAP8vz3wKcsxuWy8zMqqj3n84CuFdSAN+PiB/k9omSxgNzgc9FxCZgADC7MO/q3AbwVLP20cAhwHMRsa1C/zKSPgF8AuC1r30t999/f9n0I444gsGDB7NkyRKGDh3K73//+13GOPnkkxk7cDsPPyve1Cf4u8O2l01/ZEMX5j0rTjliO/eu7sIlQ5t2TCvd3ymnnMKSJUsYPHgwq1evZs2aNWVjHHXUUfTv35/Vq1czePBgHnjggV2W47TTTqOxsZFjjz2WlStXsm7durLpgwYNol+/fqxfv56BAwcyZ86c5s8Fb3/721mwYAFDhw5lyZIlPP3002V9Xv/613PwwQezceNG+vfvv0tMaNeuXTnllFOYN28eI0aMoLGxkQ0bNpT1GTJkCN27d2fz5s3069ePefPmlU3v3r07J598Mg8//DAnnHACCxYsYNOmTWV9jjvuOBoaGnjppZc4+OCDWbBgQdn0nj17Mnr06B1jzJs3jxdeeKGsz/HHH09TUxPbt2+ne/fuLFy4sGx6r169GDVq1I4x5s6dy+bNm8v6DBs2jK1bt9KlSxcaGhpYtGhR2fTevXszcuTIHWPMmTOHLVu2lPUZPnw4L774Ij169KCpqYnFixeXTe/bty/Dhw/fMcYDDzzA1q1by/qMHDmSjRs30qtXL7Zu3crSpUvLph9yyCEMHTqU+fPnM3LkSGbNmsW2bdvK+owaNYr169fTr18/XnzxRVasWFE2/fDDD+fYY4+lsbGR4cOH87vf/Y6IKOszevRoVq9eTf/+/dm4cSOrVq0qm17v+2nlypUMHDiQ9evX89RTT5VNHzBgAAMHDmTlypUce+yxzJo1a5cx/H7aqbPeT5Wo+QpSsZM0ICLWSDocmAFcAiwGniUViquBIyPio5JuBGZHxG153snA3XmosRHxsdx+IakYTMr9j8ntRwF3R8SwWss0atSoaGsGsv8D2cwOVJIebra7H6hzN1FErMm/nwZ+AZwYEesjoikitgM/JO0GAlgDHFWYfWBuq9a+AegjqWuzdjMz6yQtFgNJr5Z0cOlvYAywUNKRhW7vB0rb7dOA8yV1lzQYGAI8CDwEDMlnDnUjHWSeFmnT5LfAuXn+CcCv2v/QzMysXvUcM+gP/CId56Ur8JOI+LWkH0saQdpNtAr4JEBENEq6E1gEbAMujogmAEkTgXuABmBKRDTm+7gUmCrpGuARYHLHPDwzM6tHi8UgIlYAwyu0X1hjnmuBayu0TwemV7mPE5u3m5lZ5/B/IJuZmYuBmZm5GJiZGS4GZmaGi4GZmeFiYGZmuBiYmRkuBmZmhouBmZnRvqSzfpJmSFqaf/fN7ZJ0Q04te1TSyMI4E3L/pZImFNpPyOMvy/Oqox+omZlV156ks8uAmRExBJiZb0NKMhuSfz4BfBdS8QCuJF22+kTgylIByX0+XphvbJsfkZmZtVp7dhONI6WSQXk62Tjg1khmky5PfSRwJjAjIjbmEJwZwNg8rXdEzM5XML0VJ52ZmXWq9iSd9Y+ItXn6OtLVTSGllDVPNBvQQvvqCu27cNJZ2XNxQCUzOenMSWd+PyV7Y9LZtIjoU+izKSL6SroLuC4iZuX2maRLVJ8O9IiIa3L7FcAW4P7c/125/VTg0og4u9YyOenMzKz1OjzpDFhfCrjJv0tltLVJZ2vy383bzcysk7Q56YyUaFY6I6iYTjYNGJ/PKjoJeD7vTroHGCOpbz5wPAa4J097QdJJ+Syi8TjpzMysU7Un6ewh4E5JFwF/Bj6Q+08HzgKWAX8DPgIQERslXU2KvwS4KiI25r8/DdwM9ATuzj9mZtZJ2pN0tgF4Z4X2AC6uMtYUYEqF9rnAsDqW18zMdgP/B7KZmbkYmJmZi4GZmeFiYGZmuBiYmRkuBmZmhouBmZnhYmBmZrgYmJkZrSgGkhokPZKvSoqkmyWtzOln8yWNyO1OOjMz28e0ZsvgM8Djzdq+kNPPRkTE/NzmpDMzs31MvRnIA4H3Av9eR3cnnZmZ7WPqTTr7JvBF4OBm7ddK+jI5AzkituKkMyczOenMSWeZk872zvdTJS0mnUk6GzgrIj4t6XTg8xFxdv5Gvw7oBvwAWB4RVznpzMxs79WepLO3Ae+TtAqYCpwh6baIWJt3BW0FfkQ6DgBOOjMz2+e0WAwi4vKIGBgRg4Dzgfsi4h8LkZci7eMvbbc76czMbB9T7zGDSm6XdBggYD7wqdzupDMzs31Mq4pBRNxP2sdPRJxRpc8BkXTm4w5mtj/xfyCbmZmLgZmZuRiYmRkuBmZmhouBmZnRvlNLrZ18RpKZ7S28ZWBmZi4GZmbmYmBmZrQv6WywpDk5newOSd1ye/d8e1mePqgwxuW5fbGkMwvtY3PbMkmXdeDjMzOzOrQn6exrwPURcQywCbgot18EbMrt1+d+SDqedKG7oaQks+/kAtMA3ERKSDseuCD3NTOzTtKmpLN8ddEzgJ/lLrewM51sXL5Nnv7O3H8cMDUitkbEStKF7E7MP8siYkVEvEy6TPa4dj4uMzNrhbYmnR0CPBcRpfilYjrZjkSziNgm6fncfwAwuzBmcZ7mCWijKy3E3pR0dvbrmpi1rgsjDw3eckj5GA8904XHnxMnHBr8YZ341Jt2HeO0007j/Uc3ce+aLpx6RDC0b/kYf1rfhVWb0zLOe1ZcdFz5GAdaMpOTzpx05qSzZK9KOgM+DMzOu4KQdBRwd0QMk7QQGBsRq/O05aQP90l5ntty+2R2Xqp6bER8LLdfCIyOiIm1lmtPJ53tLWOYmbVGtaSzerYMSklnZwE9gN7At0hB913z1kExnayUaLZaUlfgNcAGqiedUaPdzMw6QVuTzj4E/BY4N3ebwM50smn5Nnn6fTnjYBpwfj7baDAwBHiQFHYzJJ+d1C3fx7QOeXRmZlaX9lyO4lJgqqRrgEeAybl9MvBjScuAjaQPdyKiUdKdwCJgG3BxRDQBSJpIisVsAKZERGM7lsvMzFqpPUlnK0hnAjXv8xJwXpX5rwWurdA+nRSXaWZme4D/A9nMzFwMzMzMxcDMzHAxMDMzXAzMzAwXAzMzw8XAzMxwBvI+z9c3MrOO4C0DMzNruRhI6iHpQUkLJDVK+kpuv1nSSknz88+I3C5JN+TUskcljSyMNUHS0vwzodB+gqTH8jw35PwDMzPrJPXsJtoKnBERmyW9CpglqXTp6S9ExM+a9X8P6SJ0Q0iXrv4uMFpSP+BKYBQQwMOSpkXEptzn48Ac0mUpxrLz8tZmZrab1XPV0oiIUkrIq/JPrRCEccCteb7ZpEtdHwmcCcyIiI25AMwAxuZpvSNidr666a3sTE0zM7NOUNcB5JxT/DBwDHBTRMyR9E/AtZK+DMwELouIrRSSzrJSolmt9tUV2isth5POKE86O29wE7/6cxfGDNzOca8pr9G/X9eF9VvEoF7B48+J8UPKx9iXkpmcdOakMyedJXss6ayss9QH+AVwCSmwZh3QDfgBsDwirpJ0F3BdRMzK88wkXe76dKBHRFyT268AtpCugnpdRLwrt58KXBoRZ9daFiedddwYZnbgqJZ01qqziSLiOVKozdiIWJt3BW0FfsTOy1lXSzSr1T6wQruZmXWSes4mOixvESCpJ/Bu4Im8r5985s85QGm7fRowPp9VdBLwfESsJYXXjJHUV1JfYAxwT572gqST8ljj2ZmaZmZmnaCeYwZHArfk4wZdgDsj4i5J90k6DBAwH/hU7j8dOAtYBvwN+AhARGyUdDUp5hLgqojYmP/+NHAz0JN0FpHPJDIz60QtFoOIeBR4S4X2M6r0D+DiKtOmAFMqtM8FhrW0LGZmtnv4P5DNzMzFwMzMXAzMzAwXAzMzw8XAzMxwMTAzM1wMzMwMFwMzM8Oxl4Yvdmdm7Us6GyxpTk4nu0NSt9zePd9elqcPKox1eW5fLOnMQvvY3LZM0mW74XGamVkN9ewmKiWdDQdGkAJpTgK+BlwfEccAm4CLcv+LgE25/frcD0nHA+cDQ0lJZt+R1JCveXQTKSHteOCC3NfMzDpJe5LOzgBKkZe3sDOdbFy+TZ7+znw10nHA1IjYGhErSReyOzH/LIuIFRHxMjA19zUzs07SpqQzYDnwXESU4peK6WQ7Es0iYpuk54FDcvvswrDFeZonoI2ushxOOqPjk84++IYmpi7vwrijt/P63uVj3PeXLrzwsji8Z7Bqs/jgG8rHcNKZk86cdJYcqElnVwA3511BSDoKuDsihklaSAq/WZ2nLSd9uE8CZkfEbbl9MjsvVT02Ij6W2y8ERkfExFrL4qSzvWsMM9s3dHTS2cmkoPvSlkUxnWxHolme/hpSRGZrE9DMzKyTtDXp7HFSUTg3d5vAznSyafk2efp9OeNgGnB+PttoMDAEeJAUdjMkn53UjXSQeVoHPDYzM6tTe5LOFgFTJV0DPAJMzv0nAz+WtAzYSPpwJyIaJd0JLAK2ARdHRBOApImkWMwGYEpENHbYIzQzsxa1J+lsBelMoObtLwHnVRnrWuDaCu3TSXGZZma2B/hyFGZm5stRWMfwGUlm+zZvGZiZmbcMbO/Sli0Mb12YtZ+3DMzMzFsGtv/x1oVZ63nLwMzMvGVgVklHbF14C8X2Jd4yMDOzuq5NdJSk30palJPOPpPbJ0laI2l+/jmrME+rEs2qpaaZmVnnqGfLYBvwuYg4HjgJuLiQRHZ9RIzIP9OhzYlm1VLTzMysE9STdLY2Iublv18kXbF0QI1ZWpVollPQqqWmmZlZJ2jVAeQcbv8WYA7wNmCipPHAXNLWwyZan2h2CNVT05rfv5PO2DuTzi48pokfL2vgvMFNvK5X+Rj3rO7CK9uhdzdYv0WcN7h8jGIyE8AH39DEkQeVj3HXk114VRd4VRd44WVxzqDyMYpJZwAThjRxaI/yMX65qoHe3YJXtsMr2+Hs120vG6OYdAZw0XFN9OlWPsZ/rGygf8/ghZfTspw5sHyMYtIZwKfe1MSru5aP8ZPlDQzqFTy9RfTuFpzx2vIxnHTmpLO9OulMUi/gd8C1EfGfkvoDz5LykK8GjoyIj0q6kVYkmrEzAW2X1LRay+Oks/1vjLaOsz+PYdbRqiWd1ZuB/Crg58DtEfGfABGxvjD9h8Bd+Wat5LJK7RvIqWl568BJZ2Zmnayes4lECqx5PCL+rdB+ZKHb+4FSQnmrEs1yClq11DQzM+sE9WwZvA24EHhM0vzc9i+ks4FGkHYTrQI+CW1ONLuUyqlpZmbWCepJOpsFqMKkqslkrU00q5aaZmZmncP/gWxmZi4GZmbmYmBmZrgYmJkZLgZmZoaLgZmZ4WJgZma4GJiZGS4GZmZG+5LO+kmaIWlp/t03t0vSDTm17FFJIwtjTcj9l0qaUGg/QdJjeZ4b8vWQzMysk7Qn6ewyYGZEDAFm5tuQksyG5J9PAN+FVDyAK0mXrT4RuLJUQHKfjxfmG9v+h2ZmZvVqT9LZOFIqGZSnk40Dbo1kNuny1EcCZwIzImJjDsGZAYzN03pHxOx8BdNbcdKZmVmnak/SWf+IWJsnrQP6578HsGui2YAW2ldXaK90/046w0lnTjpz0llzTjrbaU8knT0XEX0K0zdFRF9JdwHX5audImkm6RLVpwM9IuKa3H4FsAW4P/d/V24/Fbg0Is6utTxOOtv/xmjrOPvzGGYdrVrSWV1nE1VKOgPWlwJu8u9SGa2WdFarfWCFdjMz6yQt7iaqlnRGSjSbAFxHeTrZNGCipKmkg8XPR8RaSfcAXy0cNB4DXB4RGyW9IOkk0u6n8cC3O+Cxme3zOmqLy6wl7Uk6uw64U9JFwJ+BD+Rp04GzgGXA34CPAOQP/atJ8ZcAV0XExvz3p4GbgZ7A3fnHzMw6SXuSzgDeWaF/ABdXGWsKMKVC+1xgWEvLYmZmu4f/A9nMzFwMzMzMxcDMzHAxMDMzXAzMzAwXAzMzw8XAzMxo5YXqzGzf4/9itnq4GJhZi1xQ9n/1JJ1NkfS0pIWFtkmS1kian3/OKky7PCeWLZZ0ZqF9bG5bJumyQvtgSXNy+x2SunXkAzQzs5bVs2VwM3AjKXSm6PqI+HqxISegnQ8MBV4L/EbSsXnyTcC7SXkFD0maFhGLgK/lsaZK+h5wETkdzcz2H9662LvVk3T2e2BjS/2yccDUiNgaEStJF6s7Mf8si4gVEfEyMBUYl6+Iegbwszx/MTHNzMw6SXuOGUyUNB6YS8pI3kRKKJtd6FNMLWuecjYaOAR4LiK2Vei/Cyed7RzDSWcHRtIZwCVDt9Gt2de2W5c28KY+6TXp3zM47Yjy9WfRokU7ks4APjtsG12aXW5y8uIGRh6a1o1BvYK39i8f44knntjxfupC8Nk3N9Hc9x5v4NQjour7aenSpTuSzrp1ibL3U8m3GxsYM3B71ffT8uXLnXRWsEeTznLc5V0RMSzf7g88CwRwNXBkRHxU0o3A7Ii4LfebzM7LUY+NiI/l9gtJxWBS7n9Mbj8KuLt0P7U46Wz/G6Ot43iM2uPsT2NY+1VLOmvTlkFErC8M/EPgrnyzWpoZVdo3AH0kdc1bB045M7OqXFB2nzb901kp7jJ7P1A602gacL6k7pIGA0OAB0mBNkPymUPdSAeZp+Xsg98C5+b5i4lpZmbWSeqJvfwpKcz+UEmrgSuB0yWNIO0mWgV8EiAiGiXdCSwCtgEXR0RTHmcicA/QAEyJiMZ8F5cCUyVdAzxCitg0M7NOVE/S2QUVmqt+YEfEtcC1FdqnkyIxm7evIJ1tZGZme4ivTWRmZi4GZmbmYmBmZrgYmJkZLgZmZoaLgZmZ4TwDMzvA+L+YK/OWgZmZuRiYmVnbk876SZohaWn+3Te3S9INObXsUUkjC/NMyP2XSppQaD9B0mN5nhtyxoGZmXWierYMbgbGNmu7DJgZEUOAmfk2wHtIF6cbQsod+C6k4kG6ptFo0qUnriwVkNzn44X5mt+XmZntZm1NOhtHSiWD8nSyccCtkcwmXZ76SOBMYEZEbMwhODOAsXla74iYna9geitOOjMz63RtPZuof0SszX+vA/rnvwewa6LZgBbaV1dor8hJZzvHcNKZk84OxKSzV3eNsvdTyfWPNTDu6O1V30+rVq3akXTWp1uUvZ8Atgdcv7BrzffTk08+WZZ09qNfzSyb/vJ2+HZj15rvp384fdR+l3T2XET0KUzfFBF9Jd0FXBcRs3L7TNIlqk8HekTENbn9CmALcH/u/67cfipwaUSc3dIyOels/xujreN4jNrjeIy9d13dE6olnbX1bKL1pYCb/LsUFlot6axW+8AK7WZm1onauptoGimV7DrK08mmARMlTSUdLH4+ItZKugf4auGg8Rjg8ojYKOkFSScBc4DxwLfbuExmZvuUvWnroq1JZ9cBd0q6CPgz8IHcfTpwFrAM+BvwEYD8oX81Kf4S4KqIKB2U/jTpjKWewN35x8zMOlFbk84A3lmhbwAXVxlnCjClQvtcYFhLy2FmZruP/wPZzMxcDMzMzMXAzMxwMTAzM1wMzMwMFwMzM8PFwMzMcDEwMzNcDMzMjHYWA0mrckrZfElzc1uHpaCZmVnn6Igtg3dExIjCJVE7MgXNzMw6we7YTdQhKWi7YbnMzKyKtl7CuiSAeyUF8P2I+AEdl4K2Cyed7RzDSWdOOnPS2U57Iunsc2/eVja9nqSzNWvWlCWdNR/jr9vE9x5vqPl+Wrt27Z5LOqs6szQgItZIOpz0jf4SYFpHpKBFxNdr3beTzva/Mdo6jseoPY7H2L/X1dbq6KQzACJiTf79NPAL0j7/jkpBMzOzTtLmYiDp1ZIOLv1NSi9byM4UNNg1BW18PqvoJHIKGnAPMEZS33zgeExuMzOzTtKeYwb9gV9IKo3zk4j4taSH6LgUNDMz6wRtLgYRsQIYXqF9Ax2UgmZmZp3D/4FsZmYuBmZm5mJgZma4GJiZGS4GZmaGi4GZmeFiYGZmuBiYmRkuBmZmhouBmZnhYmBmZrgYmJkZ7Qy32ZMkPUO6KmpHOxR41mN4jH1gWTyGx2iLoyPisOaN+2wx2F0kza2UAuQxPMbetiwew2N0JO8mMjMzFwMzM3MxqOQHHsNjdMI4HsNj7O4xWsXHDMzMzFsGZmbmYmBmZhzAxUBSk6T5hZ/LcntXSV+VtLQw7Ut1jLNQ0n9IOii3b65jGTYX/j5L0hJJV0r6ZqH9+5J+U7h9iaQb6hjvdkn/VLg9WtKjkl5VZd6Bkn6VH/cKSTdK6l6Y/k1JayS1uM6UlkPSUEn3SVqcx71Ckuqdv1nbpHz/8yU9Iem7tZZF0pckNebHPF/S6NzeVdIzkq5raTly/3MkhaQ35tuDJG1ptu6MrzJvad1YIGmepLcWxlhY4fF9vsIYxddluaRvSeom6fS8XB8r9B2R23YZp8pzcrekrxWmH51f+z4tPJ7G/Jg+V3oNJF3b7DlZkvv3qjJWcV0trifLJX2lpfWs0usr6f48xqN5Hbmx0mPJz9FthduldeKuZv1+KWl2jWWQpFmS3lNoO0/Sr1Xl86XCGIcU+qwrrOPz83J+o9D385Im1Xpe2iUiDsgfYHOV9uuAm4Ee+fbBwKR6xgFuB/651viV5gXeCSwD3gCMAh4s9JkNPAQ05Ns/Bc6vY1n6AyuAw0hF/yHglCrzCXgQ+Ei+3QBMBr6Vb3ch/YPfbOAd9TwuoCewHBiT2w4C7gYubstrA0wCPl9YnlnVlgU4GXgA6J5vHwq8Nv/9HuCPedlUx7LcAfwB+Eq+PQhY2Np1DDgT+F21MYqPr47X5f8BpwOPAfcW+n8NmN98nBrPyQBgMfCm3PZL4EN1Pp7Dgd+UnpcKfW8Hrqlj3a+2nny2xrwVX1/gfmBUbusGfKP0nFdYP+cDPQvrxHzgrkKfPsBTwOPA62ssy7DcpwfQC1hKeh+3+P6vtY7n2y8BK4FD8+3PU+OzqL0/B+yWQSVK3+o/DlwSES8BRMSLETGpziH+ABzTyvs8DfghcHZELCetlMdK6inpNcCW3PbmPMtbSR9mNUXEeuDrwP8FPgU8GhGzqnQ/A3gpIn6U520CPguMz9/sTgcage8CF9T50D4I/DEi7s1j/g2YCFT8htRK3Uhvvk1Vph8JPBsRW/N9PxsRf8nTLgC+BTxJ+lCpKj/2U4CLgPPbucy9ayxvNdVel4+SPjT/DPSQ1F+SgLGkD9JKKj0na/J4N0k6Czg4Im6vZ8Ei4mngE8DEfN87SPpH0vtgUh1DVVtPvlBjnlqvb2n5Xga+CLxO0vAKY0wH3pv/voD0JavoH4D/D0ylxmsfEQtzv0uBLwO35vdxR9hGOqvosx00Xk0HcjHo2Wwz7n+SVuAnI+LF1g4mqSvpG8ZjrZitO+nb2DkR8QRARGwDHgH+DjgJmEP6Rv5WSQNI32afqnP87wHHk95YX6zRbyjwcLEhIl4AVpGek9Kb5RfAe1VlV1MdYy4HeknqXefyN/dZSfOBtcCSiJhfpd+9wFF5V8V3JL0dQFIP4F2kN+9PabmwjQN+HRFLgA2STsjtb2i27pxaZf7SOvYE8O/A1YVpZWOQCnZz1V6XJ9n5peNnwHmkLwnzgK1VlqXicxIR00lF6hbg01XmrSgiVpC2Vg4vtUkaRNq6/lBel1tSbT3pWW13VbXHUmH5moAFwBsrTJ4KnJ/Xif9Bep8Vldb5etaTr5CK2ntIX76g8udLW9wEfCh/MdytDuRisCUiRhR+7mjeQdJH8gv5lKSjqozTM7+Z55LepJNbsQyvAH8iffMs+hPpzf1W0ubwA4Xbf6p38IjYDnwfuDsiNrRiuYq6AWcBv8wfRHNIuzz2hOsjYgTpw+fVkip+Y4uIzcAJpG+uzwB3SPowcDbw24jYAvwcOEdSQ437u4D0oUH+XfpQWN5s3flDlflL69gbSd/aby18iy4bg1S42+JOUjGo9O12hxrPCaQPnIciYnEblwGA/FzeBlwREcvaM1YtLTyWXRaryhiPknbXXUDaStg5g9QfGALMyl8EXpE0rMby/JW0O/HHpa0V6vh8qUd+z90K/K+2zN8aXXf3HexjlpE2Kw/Ou4d+BPxI6WBftQ+NLfnN3BbbgQ8AMyX9S0R8Nbf/kfRNsQfpjfoM6Rv+M7SiGBTuY3sLfRYB5xYb8rf3I0jHHvoAj+XPsYNIu67uorZFwGnNxnw9aV/qC3Uue0UR8YqkX+fxp1bp00Tah3y/pMeACcDLwCmSVuVuh5B2xcxoPr+kfnnamyUF6fUP0uvRlmV+QNKhpGM49ar2uryOtK6OiYh1kl4B3g18hvSFodoyVHpObqa+dWQX+fVsAp7OTf8KrC3t1qpTtfVkQ0Q8V22mKo+l+fI1kHavPl5lmGmkXamnk9aFkg8AfYGVeZ3vTSoaVU8koY3PYZ2+Sdrqa83z2moH8pbBLvL+ysnAjXnzsbRCddvN9/le0qZgaQvhAdIuosMi4ulIR4+eIe22aPF4QRvMBA5SPismP+ZvADeS3gQfi4hBETEIGAy8Ox9fqeV20gfvu/KYPYEb2LkZ3Wb52/XbSAceK00/TtKQQtMI0vN3KvC6wmO5mOq7AM4lfdM7Ovc/inQwr9oWYkvL/EZSQWnNFlq11+Vm4G+Ffl8GLs0fkNXuv9Jz0uar/ko6jLQ1c2NEhKSTgA+Tvq23RrX15Moa993iY8m7Mv8P8FTeCqhkCukAePNduxcAYwvryQm0/5hRm0XERtIWYPM9CB3qQC4GzffplU41/BJpn/RCSY+QDgrfAvyl2kBVHCRpdeHnn6t1zC/2WOBfJb0vIjaRPrwaC90eIO0eWdAR99ns/gN4P3CupKWkD6ztwPV5uf6r0PevpDN5/r7SWPnYyda8K2ZcfkyLScdSHiIVmJZUexylYwalLbXvVJm/F3CLpEWSHiVtVf0OuK+wGQ/wK+DvVTiFtuAC0jGSop8Dl7PrMYNqm/A71jHSboQJtT6wmyu8Lufl12UJ6QyTf2nW708R8csWhqv0nEyqd1my0uNpJJ1JdC9pfzn590HAb5s9N2+oNWBeT94HfEnSEtJlm//YwoHsWo/l9ty2EHg1aR2sdt+rI6LsNO18zONo0nG6Ur+VwPPKpyfXqdrnS1t9g3TW1G7jy1HYLpTOh/8p8P6ImNfKeYcDP4yIE3fLwtl+TdI5wL+RThveHXklVoWLgXUYSZ8iHej636VTBc1s3+BiYGZmB/QxAzMzy1wMzMzMxcDMzFwMzMwMFwMzMwP+G75sCj72KS5XAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_count = df[\"dialect\"].value_counts()\n",
    "plt.bar(x=val_count.index, height=val_count)\n",
    "plt.yticks(list(range(5000, 60000, 5000)))\n",
    "plt.grid(axis=\"y\", ls='-.') \n",
    "print(val_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c73b41-8cc0-45b1-9b0f-7249e6a42a3c",
   "metadata": {},
   "source": [
    "The brevious chart shows that the data is imbalanced,as example:- instances number of \"EG\" category is 5 times \"TN\" or \"YE\" ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cae5853c-589e-4e22-b6a3-47cc3e34b599",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 16777216 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4560/923666030.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAutoModelForMaskedLM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"aubmindlab/bert-large-arabertv2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoModelForMaskedLM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"aubmindlab/bert-large-arabertv2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\auto\\auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    445\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 447\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    448\u001b[0m         raise ValueError(\n\u001b[0;32m    449\u001b[0m             \u001b[1;34mf\"Unrecognized configuration class {config.__class__} for this kind of AutoModel: {cls.__name__}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   1491\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1492\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mno_init_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_enable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_fast_init\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1493\u001b[1;33m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1495\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfrom_pt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m   1298\u001b[0m             )\n\u001b[0;32m   1299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1300\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbert\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_pooling_layer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1301\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertOnlyMLMHead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config, add_pooling_layer)\u001b[0m\n\u001b[0;32m    864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertEmbeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpooler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertPooler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0madd_pooling_layer\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    532\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 534\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBertLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    535\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient_checkpointing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    532\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 534\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBertLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    535\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient_checkpointing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrossattention\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertAttention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposition_embedding_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"absolute\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertIntermediate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertOutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     def forward(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    432\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLayerNorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_norm_eps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_dropout_prob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0min_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfactory_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfactory_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 16777216 bytes."
     ]
    }
   ],
   "source": [
    "# from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# inputs = tokenizer(\"Hello world!\", return_tensors=\"pt\")\n",
    "# outputs = model(**inputs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"aubmindlab/bert-large-arabertv2\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"aubmindlab/bert-large-arabertv2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8b3130-bf39-41e4-87a5-5bb546252f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(df[\"dialect\"])\n",
    "df[\"encoded_dialect\"] = le.transform(df[\"dialect\"])\n",
    "df[\"encoded_dialect\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba1b438-a453-41e4-b4e7-6a2d730f4858",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_raw, xtest_raw, ytrain, ytest = train_test_split(df[\"txt\"], df[\"encoded_dialect\"], test_size=0.15, \n",
    "                                                random_state=7, shuffle=True, stratify=df[\"dialect\"])\n",
    "\n",
    "print(f\" xtrain.shape = {xtrain.shape}\\n xtest.shape = {xtest.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8df46b-5541-42a2-8b22-a67d28853ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"txt_tokenized\"] = [arabert_tokenizer([i for i in df[\"txt\"]]\n",
    "                        # , padding=\"max_length\", truncation=True\n",
    "                       )]\n",
    "df[\"txt_tokenized\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa76bbc4-65ed-4a4b-97bb-ade43258fbcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81935fb6-f5a8-42f9-b0c4-5f8401d82982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "60b0d473-470c-436c-a3c0-9201f864006e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "881c5248c7fa4a18a4aa474e532de60e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.83k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9fa75f67ac4b4288fe0c8a9c68154e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset yelp_review_full/yelp_review_full (download: 187.06 MiB, generated: 496.94 MiB, post-processed: Unknown size, total: 684.00 MiB) to C:\\Users\\huzyfa\\.cache\\huggingface\\datasets\\yelp_review_full\\yelp_review_full\\1.0.0\\13c31a618ba62568ec8572a222a283dfc29a6517776a3ac5945fb508877dde43...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6291d8f6d1f4e16be9b1ba12ea103a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/196M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset yelp_review_full downloaded and prepared to C:\\Users\\huzyfa\\.cache\\huggingface\\datasets\\yelp_review_full\\yelp_review_full\\1.0.0\\13c31a618ba62568ec8572a222a283dfc29a6517776a3ac5945fb508877dde43. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "966340fbdb184a63bfa9333d8854cb24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2c68d2e7-78c3-4cd9-99a0-497c7bab4255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 650000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f5d09cb2-dd85-4e51-a65b-549e0b781cfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " ...]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset[\"train\"][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "da334bde-0551-4b28-8684-46ac5fbebbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' لكن بالنهايه ينتفض يغير ',\n",
       " ' يعني هذا محسوب علي البشر حيونه وحشيه وتطلبون من الغرب يحترمكم ويءمن بدينكم ولاينعتكم بالارهاب ',\n",
       " ' مبين من كلامه خليجي',\n",
       " ' يسلملي مرورك وروحك الحلوه ',\n",
       " ' وين هل الغيبه اخ محمد ',\n",
       " ' ياخي الارهابي اذا كان عراقي سعودي فلسطيني وين المشكله علي باب الفرض خليجي وماعنده رحمه وين المساس بقدسيتك اله يرضي عنك خلصت مشاكل العرب واختلفنا بجنسيت ابو الطفل المغردين سالوا من وين ورجحت وين الكارثه الي وصلتك',\n",
       " ' مطلبي يقدم استقالته وفوگاها اعتذار',\n",
       " ' خلص واله لعيونكم انا ماعندي شيء معه بالعكس من متابعيني الي بعتز فيهم خلص صافيه لبن ',\n",
       " ' يمكن سءال فات الكثير الي يصور شنو موقفه وكانه يوثق بطوله المفروض حتي المصور يحال لقضاء لان نظرات الطفله تستنجد باتجاه الكاميرا ',\n",
       " ' اولا اني ردت علي رجل جنوبي والي ذكر حجابها ثانيا انت شدعوه صايره محامي لكوهين صحيح مقوله العراق بلد الغراءب والعجاءب',\n",
       " ' واله هذا الموضوع جدا حساس ويحير اتفق معك بس انت لاتروح زايد عادي ',\n",
       " ' لا ان شاء اله اخوه يجمعنه العراق الي بكل جحيمه حلو ',\n",
       " ' يسعد مساك سيد الحرف الحزين ',\n",
       " ' ه عدوله گلبه ورم من عدنه گلك خل اتونس همه بكل شيء مارضين فهاي السفره اسمها اتونس وبكيفي ',\n",
       " ' يسلملي مرورك روعات تواصلك ',\n",
       " ' يسعد مساك بنت العم ',\n",
       " ' ماخذ اي بشر وحدي ',\n",
       " ' اتركه فتره اذا ماسال مايستحق اهتمامك ',\n",
       " ' ياكلون بخيرنه ويهينون موظفينه ',\n",
       " ' عباله يرجع صدام حسين لحكم',\n",
       " ' ربي يعطيك ويعطيهم الصحه مع قناعتي انك تنصح ولاتنصح ',\n",
       " ' اي واله ملاحظه تستحق الالتفات لها ',\n",
       " ' لان الماضي داءما فيه ريحه خيانه ',\n",
       " ' ياله بدا الحراك والتطور ',\n",
       " ' كل جماعه علي قدر عقولها ',\n",
       " ' المصيبه الشعب يشوف ابن المرجع نبي وهذا الي دمر العراق ',\n",
       " ' بالمنصور محمدنه ياخذ سلڤيات ',\n",
       " ' ابن عمي حتي الخوش بعد متگدر اتگول عليه خوش من وره الي نشوفه ونسمعه بس ابو جاسم يحب الصور ',\n",
       " ' منا ورايح بعد ميغلط بالحروف هذا درس ',\n",
       " ' لازم بالبصره دزينه شويه ',\n",
       " ' يسعد مساك استاذ نعمه يزيدني فخر تواصلك ',\n",
       " ' تستاهلون سويتوا ايران مكه ',\n",
       " ' اله يشافيك من مرض الدجل سبحان اله قبل كم سنه كنت انت ومجموعه اطفال هسه صرت تكلم عن المذهب الي دمرتوه وخليتوا العالم تضحك عليكم كل شاذ بدا يتعذر بالمذهب طيب المرجعيه وين هءلاء اخطر من داعش ',\n",
       " ' وهسه مشاكل العراق خلصت وبقت مشكله البدون ',\n",
       " ' مبروك خالو حضر عيديه اجاك العيد ',\n",
       " ' منو يخاف منها علي كيفكم تره خبلتوها لحنان بس اتهمبل واني واني ',\n",
       " ' شوفي واضحه ثقافتك بدايتها الصوره الي الظاهر انت ملتزمه جدا حنان الفتلاوي شخصيه عامه من حق اي عراقي ينقدها وياريت لو اتجوزن من الواگه ',\n",
       " ' منونه ويارب الامن والامان لمصر الغاليه ',\n",
       " ' اي واله غريب سكوتها',\n",
       " ' منونه لجنابك وكلامك الذهب ',\n",
       " ' استاذ محمد لو اعرف الجماعه شيحبون لايريدون رياضه ولافن ولاثقافه ولاتعليم ولامطبقين الدين يعني بنوا الملاعب لحوزه حيره ',\n",
       " ' هذه مراسيم شنو ومنو يتبعها مكن توضيح الاخ صاحب التغريده',\n",
       " ' انا قلت انا وانت والناس السذج ركز اخي',\n",
       " ' شبيه شريف واخو اخيته ',\n",
       " ' هاي بس يم الكعبه عرفتها هنيالك ياعراق بعدين هذا حج لو تصوير افلام كل شوي ناشرين صورتك ',\n",
       " ' كلامي غير موزون اوزنوا اقوالكم وافعالكم وغيروا مانتم فيه',\n",
       " ' ظلوا بهاي السوالف من بشر ينقد حاله تنسبوا لصدام لان انت كان يحكمك نبي واحنه صدام ',\n",
       " ' بالعافيه عليك وعلي الرجال الي تحميك الذله تليق بالبعض',\n",
       " ' ويجيك بطران يگول المرجعيه لاتدخل بالسياسه ',\n",
       " ' هذول راح نحر بيهم فلسطين ',\n",
       " ' امين يارب ينعاد عليك بتحقيق كل ماتمناه ',\n",
       " ' عيدك مبارك صحه وسلامه ',\n",
       " ' وانتم بالف خير صحه وسلامه وراحه البال ',\n",
       " ' عيدك مبارك وعساك من عواده ',\n",
       " ' وانت بخير وسلامه وربي ينعاد عليكم بكل ماتمنونه ',\n",
       " ' وانت بالف خير ويارب تحقيق كل ماتمنونه وعساكم من عواده ',\n",
       " ' من اخلاقك الحلوه كل عام وانتم بالف خير اهلنه وناسنه وفخرنه ',\n",
       " ' كل عام وانتم ترفلون بالعز والسعاده وينعاد عليكم وسط محبيكم واحبابكم ',\n",
       " ' فديت العنونه العمر كله حبيبتي ',\n",
       " ' المعارض الحقيقي الي بقي بسوريا والي طلعوا كلهم خونه باعوا بلدهم لمرتزقه ليس حبا بالاسد لكن هاي حقيقه',\n",
       " ' مو اتلومني من احچي شوف دا يصير بينه',\n",
       " ' واله اكو قسم سويت احباط عندي ',\n",
       " ' وين السمار اله يرضي عنكم ',\n",
       " ' سبحان اله احنه العراقين يوميه طالعتنه مصيبه ملتهين بيها هذا يگول السنه وذاك يگول الشيعه وعلي هل الرنه ',\n",
       " ' بس العراقين تحت المجهر بخت ستار وبخت ',\n",
       " ' ه موج البحر عوفي الحمص سولفينه عليه',\n",
       " ' علي هذا انت اتخوف گرايب الجماعه ',\n",
       " ' بكيفك بطولات انجازات قرارات',\n",
       " ' ه ايفانكا تبين كاسره خاطرك استاذ محمد ',\n",
       " ' منونه لخاطري امسحه وعلق',\n",
       " ' خوالك يموتون علي النگد لهذا في شجن بكل مايقولونه ',\n",
       " ' اني هم راح احضره زين نبهتني',\n",
       " ' لحد الان ماعرف دافع جوابه ردي كان طبيعي مافيه ازعاج ',\n",
       " ' مبدع ومحد داري بيك ',\n",
       " ' لا ابد مامنزله ايدي ولاشكلي لاتسوينه مشكله اله يرضي عنك',\n",
       " ' اقتراحاتك رهيبه كلك افكار',\n",
       " ' حج مبرور وسعي مشكور ',\n",
       " ' وهو شخسران نوري المالكي ولد الخايبات الي بقوا يخليهم حطب لفزعاته خاف اكو بلد لسه اسمه العراق',\n",
       " ' التسرع بالحكم او اتخاذ القرار ولو علي ماضن متحتاج نصيحه ',\n",
       " ' هذا مريض عنده حاله نفسيه ',\n",
       " ' صعبه ان يرجع حرا ',\n",
       " ' كل هذا ومامقصوده اذا مقصوده شلون ',\n",
       " ' صح لسانك الجهل افه',\n",
       " ' ياله عليه تكاليف حفله حنتك ',\n",
       " ' ماعرف هاي حكومه لو علوه مخضر ',\n",
       " ' ه واله اني هم شاكه احنه المقصودين لان الدلاءل كلها لاتشير علينا',\n",
       " ' منونه سيد يسعد صباحك ',\n",
       " ' اسمعت لو ناديت حيا ',\n",
       " ' وربك متاخذغير القهر والتعب والضيم والمرض ويخلص عمرها حتي يرضي وتربي اولاده هاي بس المراءه العربيه ',\n",
       " ' شلونك شلون صحتك عافيتك شلون الاهل ان شاء اله زنين ']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in df[\"txt\"].iloc[:90]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7def4aa-3cac-4168-9a90-d764c8261edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0322d58a-d5bf-4009-afee-939a56937b82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72671322-4c0a-4026-9d6c-b76e88b25a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066d5d53-ec00-47fb-afc7-a6ffd014f48e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b9e59e-68c2-40a1-a7b2-1e64f9573576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a736e2b-d77a-44ba-81c8-8ea3da4268f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe65dbf-d63e-4744-8fa3-873571539c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fb6510-b4d0-474a-8600-81eb5957f1d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbae062-ebe0-418e-8e7c-40b7206a089a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095c4799-dd34-4017-8cb3-911e1ff8f278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b973d5b-28d5-4077-8b19-7f2d2562ec6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745f51c5-bb19-4ffe-9b26-e084e2665dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec39913-da14-4298-96f6-fc648e1970e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ac227e-0fd7-4d72-873c-19c067240194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2770018a-2e9d-4b93-a619-3088b996bc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "le.inverse_transform(df[\"encoded_dialect\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c8b75f9-4a1b-4853-8493-2fd904e635e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.merge(txt_df, label_df, left_index=True, right_index=True)\n",
    "# df = pd.concat([txt_df, label_df], axis=1)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a8a264-cf4b-4b9e-8640-20489de3875f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
